{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Country-data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the missing data\n",
    "print((df.isnull().sum()/len(df))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Details\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the columns of the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distplot to identify the data distribution of each column\n",
    "plt.figure(figsize=(15,20))\n",
    "feature=['child_mort', 'exports', 'health', 'imports', 'income','inflation', 'life_expec', 'total_fer', 'gdpp']\n",
    "for i in enumerate(feature):\n",
    "    plt.subplot(6,2,i[0]+1)\n",
    "    sns.distplot(df[i[1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above plot its found that 'child_mort', 'exports', 'health', 'imports', 'inflation', 'gdpp', 'life_expec' are almost normally distributed. But for 'income' there are much number of countries income around 400k and for 'total_fer' there are much number of countries total fertility rate around 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the 'exports', 'health' & 'import' column are the %age of 'gdpp' so, convering to its actual value\n",
    "df['exports']=(df['gdpp']*df['exports'])/100\n",
    "df['health']=(df['gdpp']*df['health'])/100\n",
    "df['imports']=(df['gdpp']*df['imports'])/100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot to visualise the outliers\n",
    "plt.figure(figsize=(15,20))\n",
    "feature=['child_mort', 'exports', 'health', 'imports', 'income','inflation', 'life_expec', 'total_fer', 'gdpp']\n",
    "for i in enumerate(feature):\n",
    "    plt.subplot(6,2,i[0]+1)\n",
    "    sns.boxplot(df[i[1]],orient='v')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can define from the above Boxplot, all the variable has outliers so we will cap the outliers as we do not want to loose any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Capping of \"child_mort\" column\n",
    "q1= df['child_mort'].quantile(0.01)\n",
    "q2= df['child_mort'].quantile(0.99)\n",
    "df['child_mort'][df['child_mort']<=q1]=q1\n",
    "df['child_mort'][df['child_mort']>=q2]=q2\n",
    "\n",
    "# Outlier Capping of \"exports\" column\n",
    "q3= df['exports'].quantile(0.01)\n",
    "q4= df['exports'].quantile(0.99)\n",
    "df['exports'][df['exports']<=q3]=q3\n",
    "df['exports'][df['exports']>=q4]=q4\n",
    "\n",
    "# Outlier Capping of \"health\" column\n",
    "q5= df['health'].quantile(0.01)\n",
    "q6= df['health'].quantile(0.99)\n",
    "df['health'][df['health']<=q5]=q5\n",
    "df['health'][df['health']>=q6]=q6\n",
    "\n",
    "# Outlier Capping of \"imports\" column\n",
    "q7= df['imports'].quantile(0.01)\n",
    "q8= df['imports'].quantile(0.99)\n",
    "df['imports'][df['imports']<=q7]=q7\n",
    "df['imports'][df['imports']>=q8]=q8\n",
    "\n",
    "# Outlier Capping of \"income\" column\n",
    "q9= df['income'].quantile(0.01)\n",
    "q10= df['income'].quantile(0.99)\n",
    "df['income'][df['income']<=q9]=q9\n",
    "df['income'][df['income']>=q10]=q10\n",
    "\n",
    "# Outlier Capping of \"inflation\" column\n",
    "q11= df['inflation'].quantile(0.01)\n",
    "q12= df['inflation'].quantile(0.99)\n",
    "df['inflation'][df['inflation']<=q11]=q11\n",
    "df['inflation'][df['inflation']>=q12]=q12\n",
    "\n",
    "# Outlier Capping of \"life_expec\" column\n",
    "q13= df['life_expec'].quantile(0.01)\n",
    "q14= df['life_expec'].quantile(0.99)\n",
    "df['life_expec'][df['life_expec']<=q13]=q13\n",
    "df['life_expec'][df['life_expec']>=q14]=q14\n",
    "\n",
    "# Outlier Capping of \"total_fer\" column\n",
    "q15= df['total_fer'].quantile(0.01)\n",
    "q16= df['total_fer'].quantile(0.99)\n",
    "df['total_fer'][df['total_fer']<=q15]=q15\n",
    "df['total_fer'][df['total_fer']>=q16]=q16\n",
    "\n",
    "# Outlier Capping of \"gdpp\" column\n",
    "q17= df['gdpp'].quantile(0.01)\n",
    "q18= df['gdpp'].quantile(0.99)\n",
    "df['gdpp'][df['gdpp']<=q17]=q17\n",
    "df['gdpp'][df['gdpp']>=q18]=q18\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot after Capping to 1% and 99% \n",
    "plt.figure(figsize=(15,20))\n",
    "feature=['child_mort', 'exports', 'health', 'imports', 'income','inflation', 'life_expec', 'total_fer', 'gdpp']\n",
    "for i in enumerate(feature):\n",
    "    plt.subplot(6,2,i[0]+1)\n",
    "    sns.boxplot(df[i[1]],orient='v')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy data\n",
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the 'country' column from the df dataframe \n",
    "df.drop('country', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the Variable\n",
    "Scale=StandardScaler()\n",
    "df2=Scale.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to Dataframe\n",
    "df2=pd.DataFrame(df2)\n",
    "df2.columns=['child_mort', 'exports', 'health', 'imports', 'income','inflation', 'life_expec', 'total_fer', 'gdpp']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hopkins Statistics:\n",
    "The Hopkins statistic, is a statistic which gives a value which indicates the cluster tendency, in other words: how well the data can be clustered.\n",
    "\n",
    "- If the value is between {0.01, ...,0.3}, the data is regularly spaced.\n",
    "\n",
    "- If the value is around 0.5, it is random.\n",
    "\n",
    "- If the value is between {0.7, ..., 0.99}, it has a high tendency to cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hopkin Score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import sample\n",
    "from numpy.random import uniform\n",
    "import numpy as np\n",
    "from math import isnan\n",
    " \n",
    "def hopkins(X):\n",
    "    d = X.shape[1]\n",
    "    #d = len(vars) # columns\n",
    "    n = len(X) # rows\n",
    "    m = int(0.1 * n) \n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n",
    " \n",
    "    rand_X = sample(range(0, n, 1), m)\n",
    " \n",
    "    ujd = []\n",
    "    wjd = []\n",
    "    for j in range(0, m):\n",
    "        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n",
    "        ujd.append(u_dist[0][1])\n",
    "        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n",
    "        wjd.append(w_dist[0][1])\n",
    " \n",
    "    H = sum(ujd) / (sum(ujd) + sum(wjd))\n",
    "    if isnan(H):\n",
    "        print(ujd, wjd)\n",
    "        H = 0\n",
    " \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hopkin score for df2\n",
    "hopkins(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Value of K for K-Mean Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score for K-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silhouette analysis\n",
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "for num_clusters in range_n_clusters:\n",
    "    \n",
    "    # intialise kmeans\n",
    "    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n",
    "    kmeans.fit(df2)\n",
    "    \n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    # silhouette score\n",
    "    silhouette_avg = silhouette_score(df2, cluster_labels)\n",
    "    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# silhouette score curve for cluster 2 to 10\n",
    "ss=[]\n",
    "for k in range(2,10):\n",
    "    kmeans= KMeans(n_clusters= k).fit(df2)\n",
    "    ss.append([k,silhouette_score(df2, kmeans.labels_)])\n",
    "plt.plot(pd.DataFrame(ss)[0],pd.DataFrame(ss)[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Elbow Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd=[]\n",
    "for k in range(2,10):\n",
    "    model= KMeans(n_clusters= k).fit(df2)\n",
    "    ssd.append([k,model.inertia_])\n",
    "plt.plot(pd.DataFrame(ssd)[0],pd.DataFrame(ssd)[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, from the Silhouette score curve & Elbow curve we can conclue that k=3 is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering with k=3\n",
    "kmean_= KMeans(n_clusters=3, random_state=100)\n",
    "kmean_.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels of clusters\n",
    "kmean_.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatination of Kmean Label column with the DataFrame\n",
    "df_cluster=pd.concat([df1,pd.Series(kmean_.labels_)],axis=1)\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the columns\n",
    "df_cluster.columns=['country', 'child_mort', 'exports', 'health', 'imports', 'income','inflation', 'life_expec',\n",
    "                   'total_fer','gdpp','KMean_Labels']\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Point in each cluster\n",
    "df_cluster.KMean_Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean of each Label\n",
    "df_cluster.drop('country',axis=1).groupby('KMean_Labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,80))\n",
    "df_cluster[['child_mort','income','gdpp','KMean_Labels']].groupby('KMean_Labels').mean().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After plotting the 3 clusters on basis of Child mortality, income & GDP, it is found that the  countries in Cluster no 2 are lowest among all as per K-mean clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cluster[df_cluster['KMean_Labels']==2].sort_values(['gdpp','child_mort','income'],ascending=[True,False,True]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identified 10 Countries by K-Mean clustering that are in the direst need of aid, choosed on the basis of [gdpp, child_mort and income]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.subplot(3,1,1)\n",
    "sns.scatterplot(x= df_cluster['gdpp'],y= df_cluster['income'],hue= df_cluster['KMean_Labels'], palette='Set1');\n",
    "plt.subplot(3,1,2)\n",
    "sns.scatterplot(x= df_cluster['child_mort'],y= df_cluster['income'],hue= df_cluster['KMean_Labels'], palette='Set1')\n",
    "plt.subplot(3,1,3)\n",
    "sns.scatterplot(x= df_cluster['child_mort'],y= df_cluster['gdpp'],hue= df_cluster['KMean_Labels'], palette='Set1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the Clusters on the basis of income, child mortality & gdp by K-mean cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.subplot(3,1,1)\n",
    "sns.boxplot(x= df_cluster['KMean_Labels'],y= df_cluster['income'],palette='Set1');\n",
    "plt.subplot(3,1,2)\n",
    "sns.boxplot(x= df_cluster['KMean_Labels'],y= df_cluster['child_mort'],palette='Set1')\n",
    "plt.subplot(3,1,3)\n",
    "sns.boxplot(x= df_cluster['KMean_Labels'],y= df_cluster['gdpp'],palette='Set1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can visualise, Cluster 2 countries has Lowset income, highest child mortality & lowest gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the previous scaled data\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# single linkage\n",
    "plt.figure(figsize=(30,10))\n",
    "mergings = linkage(df2, method=\"single\", metric='euclidean')\n",
    "dendrogram(mergings)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can visualise the Hierarchical clustering by single linkage is completly unreadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# complete linkage\n",
    "plt.figure(figsize=(30,10))\n",
    "mergings = linkage(df2, method=\"complete\", metric='euclidean')\n",
    "dendrogram(mergings)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can have a clear view of clusters at Hierarchical clustering by complete linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score for Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Silhouette Score for different clusters from 2 to 10\n",
    "ssi=[]\n",
    "for k in range(2,10):\n",
    "    cluster_labels = cut_tree(mergings, n_clusters=k).reshape(-1, )\n",
    "    ssi.append([k,silhouette_score(df2, cluster_labels)])\n",
    "plt.plot(pd.DataFrame(ssi)[0],pd.DataFrame(ssi)[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By the Silhouette Curve we found 3 clusters are optimum and by Hierarchical Clustering using complete linkage, x axis consists of countries and y axis consists of Euclidean distance between the clusters,to get the largest distance we count the number of lines on the diagram and determine optimal numbers of clusters, so we have choosed 3 clusters as optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 clusters\n",
    "cluster_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign cluster labels\n",
    "df_cluster['Hcal_labels'] = cluster_labels\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Point at each cluster\n",
    "df_cluster.Hcal_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean of each Label\n",
    "df_cluster.drop(['country','KMean_Labels'],axis=1).groupby('Hcal_labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,80))\n",
    "df_cluster[['child_mort','income','gdpp','Hcal_labels']].groupby('Hcal_labels').mean().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After plotting the 3 clusters on basis of Child mortality, income & GDP, it is found that the  countries in Cluster no 0 are lowest among all as per Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[df_cluster['Hcal_labels']==0].sort_values(['gdpp','child_mort','income'],ascending=[True,False,True]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.subplot(3,1,1)\n",
    "sns.scatterplot(x= df_cluster['gdpp'],y= df_cluster['income'],hue= df_cluster['Hcal_labels'], palette='Set1');\n",
    "plt.subplot(3,1,2)\n",
    "sns.scatterplot(x= df_cluster['child_mort'],y= df_cluster['income'],hue= df_cluster['Hcal_labels'], palette='Set1')\n",
    "plt.subplot(3,1,3)\n",
    "sns.scatterplot(x= df_cluster['child_mort'],y= df_cluster['gdpp'],hue= df_cluster['Hcal_labels'], palette='Set1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the Clusters on the basis of income, child mortality & gdp by Hierarchical cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.subplot(3,1,1)\n",
    "sns.boxplot(x= df_cluster['Hcal_labels'],y= df_cluster['income'],palette='Set1');\n",
    "plt.subplot(3,1,2)\n",
    "sns.boxplot(x= df_cluster['Hcal_labels'],y= df_cluster['child_mort'],palette='Set1')\n",
    "plt.subplot(3,1,3)\n",
    "sns.boxplot(x= df_cluster['Hcal_labels'],y= df_cluster['gdpp'],palette='Set1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can visualise, Cluster 0 countries has Lowset income, highest child mortality & lowest gdp as per Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Suggestion List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Country List By Hirarchical CLustering\n",
    "df_cluster[df_cluster['Hcal_labels']==0].sort_values(['gdpp','child_mort','income'],ascending=[True,False,True]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country List By K-mean CLustering\n",
    "df_cluster[df_cluster['KMean_Labels']==2].sort_values(['gdpp','child_mort','income'],ascending=[True,False,True]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusion:\n",
    "\n",
    "### As we have found that the same list of countries for both the clusters(K-mean & Hierarchical) which are in the direst need of aid, sorted by these three variables - [gdpp, child_mort and income], but K-means is more suitable as the data set is large and the the value of k can be identified by Silhouette curve & elbow curve easily in statistical way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
